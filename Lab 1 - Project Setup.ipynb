{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Set up the Lab Environment\n",
    "\n",
    "In this lab you will set up your Azure AI Foundry resource and project, deploy essential language and embedding models, create necessary services, and setup necessary permissions and configurations.Finally, youâ€™ll validate your setup by sending a test chat completion to your deployed model, ensuring your environment is ready for AI agent development in subsequent labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Test your lab environment\n",
    "\n",
    "To test that your lab was setup successfully, run the below code that sends a message to the deployed model, asking it to tell a joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using token-based authentication using DefaultAzureCredential\n",
    "\n",
    "This method is recommended because it provides secure, seamless authentication using your Azure login and supports best practices for managing credentials in both development and production environments. Also, these labs were built using DefaultAzureCredential, so using this method will be the easiest approach for running the code in subsequent labs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = AIProjectClient(\n",
    "    endpoint=os.getenv(\"AIPROJECT_ENDPOINT\"),\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with your model\n",
    "\n",
    "This code sends a chat message to your deployed model and prints the AI's response, allowing you to verify your environment is working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the gpt-4.1 model\n",
    "# Make sure you run the above code cell to instantiate the client first\n",
    "chat = project.inference.get_chat_completions_client()\n",
    "response = chat.complete(\n",
    "    model=os.getenv(\"CHAT_MODEL\"), # gpt-4o model from your project\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI assistant that tells jokes for toddlers.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Hey, can you tell a joke about teddy bear?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
